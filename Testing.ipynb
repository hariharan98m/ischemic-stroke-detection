{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow._api.v1.layers import *\n",
    "import tensorlayer as tl\n",
    "from Preprocessing import *\n",
    "from metrics import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "13\n",
      "28\n",
      "(1, 240, 240, 153)\n",
      "(1, 240, 240, 153)\n",
      "(1, 240, 240, 153)\n",
      "(1, 240, 240, 153)\n",
      "{'DWI': {'mean': 21.078682, 'std': 44.95277}, 'Flair': {'mean': 24.302284, 'std': 50.49608}, 'T1': {'mean': 31.60154, 'std': 63.932735}, 'T2': {'mean': 44.153976, 'std': 92.98761}}\n",
      " HGG Validation\n",
      "finished 12\n",
      "finished 13\n",
      " HGG Train\n",
      "finished 1\n",
      "finished 2\n",
      "finished 3\n",
      "finished 4\n",
      "finished 5\n",
      "finished 6\n",
      "finished 7\n",
      "finished 8\n",
      "finished 9\n",
      "finished 10\n",
      "finished 11\n",
      "finished 12\n",
      "(1836, 240, 240, 4)\n",
      "(1836, 240, 240)\n",
      "Preparing Testing Data\n",
      "finished 14\n",
      "finished 15\n",
      "(306, 240, 240, 4)\n",
      "(306, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] [!] checkpoint exists ...\n",
      "[TL] [!] test_samples/all exists ...\n"
     ]
    }
   ],
   "source": [
    "task = \"all\"\n",
    "modelName = \"./checkpoint/unet_attention_{}.ckpt\".format(all)\n",
    "\n",
    "# FOLDERS Initialization\n",
    "save_dir = \"checkpoint\"\n",
    "tl.files.exists_or_mkdir(save_dir)\n",
    "tl.files.exists_or_mkdir(\"test_samples/{}\".format(task))\n",
    "\n",
    "# Prepare Dataset\n",
    "XTrain = dataset.X_train_input\n",
    "yTrain = dataset.X_train_target[:, :, :, np.newaxis]\n",
    "XTest = dataset.X_dev_input\n",
    "yTest = dataset.X_dev_target[:, :, :, np.newaxis]\n",
    "yTrain = (yTrain > 0).astype(int)\n",
    "yTest = (yTest > 0).astype(int)\n",
    "\n",
    "# Normalize data\n",
    "XTrain, yTrain = NormalizeImageSet(XTrain, yTrain)\n",
    "XTest, yTest = NormalizeImageSet(XTest, yTest)\n",
    "\n",
    "# hyperparams \n",
    "batch_size = 10\n",
    "lr = 0.0001\n",
    "n_epoch = 120\n",
    "evalEpoch = 100\n",
    "dropout_value = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Input: size of image: 240 240 4\n",
      " * Input: size of image: 240 240 4\n",
      "[TL]   [*] geting variables with u_net\n",
      "[TL]   got   0: u_net_attention/conv1_l1_1/kernel:0   (3, 3, 4, 64)\n",
      "[TL]   got   1: u_net_attention/conv1_l1_1/bias:0   (64,)\n",
      "[TL]   got   2: u_net_attention/batch_normalization/gamma:0   (64,)\n",
      "[TL]   got   3: u_net_attention/batch_normalization/beta:0   (64,)\n",
      "[TL]   got   4: u_net_attention/convl1_2/kernel:0   (3, 3, 4, 64)\n",
      "[TL]   got   5: u_net_attention/convl1_2/bias:0   (64,)\n",
      "[TL]   got   6: u_net_attention/batch_normalization_1/gamma:0   (64,)\n",
      "[TL]   got   7: u_net_attention/batch_normalization_1/beta:0   (64,)\n",
      "[TL]   got   8: u_net_attention/conv1_l2_1/kernel:0   (3, 3, 64, 128)\n",
      "[TL]   got   9: u_net_attention/conv1_l2_1/bias:0   (128,)\n",
      "[TL]   got  10: u_net_attention/batch_normalization_2/gamma:0   (128,)\n",
      "[TL]   got  11: u_net_attention/batch_normalization_2/beta:0   (128,)\n",
      "[TL]   got  12: u_net_attention/convl2_2/kernel:0   (3, 3, 64, 128)\n",
      "[TL]   got  13: u_net_attention/convl2_2/bias:0   (128,)\n",
      "[TL]   got  14: u_net_attention/batch_normalization_3/gamma:0   (128,)\n",
      "[TL]   got  15: u_net_attention/batch_normalization_3/beta:0   (128,)\n",
      "[TL]   got  16: u_net_attention/conv1_l3_1/kernel:0   (3, 3, 128, 256)\n",
      "[TL]   got  17: u_net_attention/conv1_l3_1/bias:0   (256,)\n",
      "[TL]   got  18: u_net_attention/batch_normalization_4/gamma:0   (256,)\n",
      "[TL]   got  19: u_net_attention/batch_normalization_4/beta:0   (256,)\n",
      "[TL]   got  20: u_net_attention/convl3_2/kernel:0   (3, 3, 128, 256)\n",
      "[TL]   got  21: u_net_attention/convl3_2/bias:0   (256,)\n",
      "[TL]   got  22: u_net_attention/batch_normalization_5/gamma:0   (256,)\n",
      "[TL]   got  23: u_net_attention/batch_normalization_5/beta:0   (256,)\n",
      "[TL]   got  24: u_net_attention/conv1_l4_1/kernel:0   (3, 3, 256, 512)\n",
      "[TL]   got  25: u_net_attention/conv1_l4_1/bias:0   (512,)\n",
      "[TL]   got  26: u_net_attention/batch_normalization_6/gamma:0   (512,)\n",
      "[TL]   got  27: u_net_attention/batch_normalization_6/beta:0   (512,)\n",
      "[TL]   got  28: u_net_attention/convl4_2/kernel:0   (3, 3, 256, 512)\n",
      "[TL]   got  29: u_net_attention/convl4_2/bias:0   (512,)\n",
      "[TL]   got  30: u_net_attention/batch_normalization_7/gamma:0   (512,)\n",
      "[TL]   got  31: u_net_attention/batch_normalization_7/beta:0   (512,)\n",
      "[TL]   got  32: u_net_attention/conv1_l5_1/kernel:0   (3, 3, 512, 1024)\n",
      "[TL]   got  33: u_net_attention/conv1_l5_1/bias:0   (1024,)\n",
      "[TL]   got  34: u_net_attention/batch_normalization_8/gamma:0   (1024,)\n",
      "[TL]   got  35: u_net_attention/batch_normalization_8/beta:0   (1024,)\n",
      "[TL]   got  36: u_net_attention/convl5_2/kernel:0   (3, 3, 512, 1024)\n",
      "[TL]   got  37: u_net_attention/convl5_2/bias:0   (1024,)\n",
      "[TL]   got  38: u_net_attention/batch_normalization_9/gamma:0   (1024,)\n",
      "[TL]   got  39: u_net_attention/batch_normalization_9/beta:0   (1024,)\n",
      "[TL]   got  40: u_net_attention/deconv_1/kernel:0   (3, 3, 512, 1024)\n",
      "[TL]   got  41: u_net_attention/deconv_1/bias:0   (512,)\n",
      "[TL]   got  42: u_net_attention/attn1_g1/kernel:0   (1, 1, 512, 512)\n",
      "[TL]   got  43: u_net_attention/attn1_g1/bias:0   (512,)\n",
      "[TL]   got  44: u_net_attention/attn1_x1/kernel:0   (1, 1, 512, 512)\n",
      "[TL]   got  45: u_net_attention/attn1_x1/bias:0   (512,)\n",
      "[TL]   got  46: u_net_attention/attn1_psi_conv/kernel:0   (1, 1, 512, 512)\n",
      "[TL]   got  47: u_net_attention/attn1_psi_conv/bias:0   (512,)\n",
      "[TL]   got  48: u_net_attention/conv1_ul1_1/kernel:0   (3, 3, 1024, 512)\n",
      "[TL]   got  49: u_net_attention/conv1_ul1_1/bias:0   (512,)\n",
      "[TL]   got  50: u_net_attention/batch_normalization_10/gamma:0   (512,)\n",
      "[TL]   got  51: u_net_attention/batch_normalization_10/beta:0   (512,)\n",
      "[TL]   got  52: u_net_attention/convul1_2/kernel:0   (3, 3, 1024, 512)\n",
      "[TL]   got  53: u_net_attention/convul1_2/bias:0   (512,)\n",
      "[TL]   got  54: u_net_attention/batch_normalization_11/gamma:0   (512,)\n",
      "[TL]   got  55: u_net_attention/batch_normalization_11/beta:0   (512,)\n",
      "[TL]   got  56: u_net_attention/deconv_2/kernel:0   (3, 3, 256, 512)\n",
      "[TL]   got  57: u_net_attention/deconv_2/bias:0   (256,)\n",
      "[TL]   got  58: u_net_attention/attn2_g1/kernel:0   (1, 1, 256, 256)\n",
      "[TL]   got  59: u_net_attention/attn2_g1/bias:0   (256,)\n",
      "[TL]   got  60: u_net_attention/attn2_x1/kernel:0   (1, 1, 256, 256)\n",
      "[TL]   got  61: u_net_attention/attn2_x1/bias:0   (256,)\n",
      "[TL]   got  62: u_net_attention/attn2_psi_conv/kernel:0   (1, 1, 256, 256)\n",
      "[TL]   got  63: u_net_attention/attn2_psi_conv/bias:0   (256,)\n",
      "[TL]   got  64: u_net_attention/conv1_ul2_1/kernel:0   (3, 3, 512, 256)\n",
      "[TL]   got  65: u_net_attention/conv1_ul2_1/bias:0   (256,)\n",
      "[TL]   got  66: u_net_attention/batch_normalization_12/gamma:0   (256,)\n",
      "[TL]   got  67: u_net_attention/batch_normalization_12/beta:0   (256,)\n",
      "[TL]   got  68: u_net_attention/convul2_2/kernel:0   (3, 3, 512, 256)\n",
      "[TL]   got  69: u_net_attention/convul2_2/bias:0   (256,)\n",
      "[TL]   got  70: u_net_attention/batch_normalization_13/gamma:0   (256,)\n",
      "[TL]   got  71: u_net_attention/batch_normalization_13/beta:0   (256,)\n",
      "[TL]   got  72: u_net_attention/deconv_3/kernel:0   (3, 3, 128, 256)\n",
      "[TL]   got  73: u_net_attention/deconv_3/bias:0   (128,)\n",
      "[TL]   got  74: u_net_attention/attn3_g1/kernel:0   (1, 1, 128, 128)\n",
      "[TL]   got  75: u_net_attention/attn3_g1/bias:0   (128,)\n",
      "[TL]   got  76: u_net_attention/attn3_x1/kernel:0   (1, 1, 128, 128)\n",
      "[TL]   got  77: u_net_attention/attn3_x1/bias:0   (128,)\n",
      "[TL]   got  78: u_net_attention/attn3_psi_conv/kernel:0   (1, 1, 128, 128)\n",
      "[TL]   got  79: u_net_attention/attn3_psi_conv/bias:0   (128,)\n",
      "[TL]   got  80: u_net_attention/conv1_ul3_1/kernel:0   (3, 3, 256, 128)\n",
      "[TL]   got  81: u_net_attention/conv1_ul3_1/bias:0   (128,)\n",
      "[TL]   got  82: u_net_attention/batch_normalization_14/gamma:0   (128,)\n",
      "[TL]   got  83: u_net_attention/batch_normalization_14/beta:0   (128,)\n",
      "[TL]   got  84: u_net_attention/convul3_2/kernel:0   (3, 3, 256, 128)\n",
      "[TL]   got  85: u_net_attention/convul3_2/bias:0   (128,)\n",
      "[TL]   got  86: u_net_attention/batch_normalization_15/gamma:0   (128,)\n",
      "[TL]   got  87: u_net_attention/batch_normalization_15/beta:0   (128,)\n",
      "[TL]   got  88: u_net_attention/deconv_4/kernel:0   (3, 3, 64, 128)\n",
      "[TL]   got  89: u_net_attention/deconv_4/bias:0   (64,)\n",
      "[TL]   got  90: u_net_attention/attn4_g1/kernel:0   (1, 1, 64, 64)\n",
      "[TL]   got  91: u_net_attention/attn4_g1/bias:0   (64,)\n",
      "[TL]   got  92: u_net_attention/attn4_x1/kernel:0   (1, 1, 64, 64)\n",
      "[TL]   got  93: u_net_attention/attn4_x1/bias:0   (64,)\n",
      "[TL]   got  94: u_net_attention/attn4_psi_conv/kernel:0   (1, 1, 64, 64)\n",
      "[TL]   got  95: u_net_attention/attn4_psi_conv/bias:0   (64,)\n",
      "[TL]   got  96: u_net_attention/conv1_ul4_1/kernel:0   (3, 3, 128, 64)\n",
      "[TL]   got  97: u_net_attention/conv1_ul4_1/bias:0   (64,)\n",
      "[TL]   got  98: u_net_attention/batch_normalization_16/gamma:0   (64,)\n",
      "[TL]   got  99: u_net_attention/batch_normalization_16/beta:0   (64,)\n",
      "[TL]   got 100: u_net_attention/convul4_2/kernel:0   (3, 3, 128, 64)\n",
      "[TL]   got 101: u_net_attention/convul4_2/bias:0   (64,)\n",
      "[TL]   got 102: u_net_attention/batch_normalization_17/gamma:0   (64,)\n",
      "[TL]   got 103: u_net_attention/batch_normalization_17/beta:0   (64,)\n",
      "[TL]   got 104: u_net_attention/conv_output/kernel:0   (1, 1, 64, 1)\n",
      "[TL]   got 105: u_net_attention/conv_output/bias:0   (1,)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    sess = tf.Session(config = tf.ConfigProto(allow_soft_placement = True))\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        \n",
    "        XInput = tf.placeholder(dtype = tf.float32, shape = [batch_size, 240, 240, 4], name = \"input_image\")\n",
    "        yInput = tf.placeholder(dtype = tf.float32, shape = [batch_size, 240, 240, 1], name = \"ground_truth\")\n",
    "        dropout_ph = tf.placeholder_with_default(tf.cast(dropout_value, dtype = tf.float32), shape = [], name = \"dropout_probability\")\n",
    "        \n",
    "        yOutput = UNetWithAttention(XInput, reuse = False, n_out = 1, dropout_ph = dropout_ph, batchNorm = True)\n",
    "        \n",
    "        yOutputTest = UNetWithAttention(XInput, reuse = True, n_out = 1, dropout_ph = dropout_ph, batchNorm = True)\n",
    "        \n",
    "        # defining loss\n",
    "        loss = 1 - tl.cost.dice_coe(yOutput, yInput, axis = [0, 1, 2, 3])\n",
    "        testLoss = 1 - tl.cost.dice_coe(yOutputTest, yInput, axis = [0, 1, 2, 3])\n",
    "    \n",
    "    \n",
    "    trainVar = tl.layers.get_variables_with_name('u_net', True, True)\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope('learning_rate'):\n",
    "            lrVar = tf.Variable(lr, trainable = False)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(lrVar).minimize(loss, var_list = trainVar)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # load existing model if exist\n",
    "    saver = tf.train.Saver(var_list = trainVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint\\u_net_attention_all.ckpt\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\Brain Tumor Research\\Brain-Tumor-Attn-TF\\metrics.py:20: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  P_i = TP_i/(TP_i+FP_i) #Precision for ith test-reference sample\n",
      "D:\\Projects\\Brain Tumor Research\\Brain-Tumor-Attn-TF\\metrics.py:21: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  R_i = TP_i/(TP_i+FN_i) #Recall for ith test-reference sample\n",
      "D:\\Projects\\Brain Tumor Research\\Brain-Tumor-Attn-TF\\metrics.py:23: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  Accuracy_i = (TP_i+TN_i)/(TP_i+TN_i+FP_i+FN_i) #Accuracy for ith test-reference sample\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      "(240, 240, 1)\n",
      " **                 test -- loss: 0.938233\n",
      " task: all\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2655\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2656\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2657\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c06b0bbd585d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mm_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mavg_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm_avg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mexportcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Projects\\Brain Tumor Research\\Brain-Tumor-Attn-TF\\metrics.py\u001b[0m in \u001b[0;36mexportcsv\u001b[1;34m(metric_dict)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mexportcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmetric_dict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./metrics.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    449\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                     mgr = init_ndarray(data, index, columns, dtype=dtype,\n\u001b[1;32m--> 451\u001b[1;33m                                        copy=copy)\n\u001b[0m\u001b[0;32m    452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                 \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_ndarray\u001b[1;34m(values, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;31m# by definition an array here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[1;31m# the dtypes will be coerced to a single dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprep_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mprep_ndarray\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'len'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[1;31m# GH#21861\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2658\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2659\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "m = {'Precision':[], 'Recall':[], 'Accuracy':[], 'F_score':[], 'Confusion':[[],[],[],[]]}\n",
    "saver.restore(sess, tf.train.latest_checkpoint(\"./checkpoint\"))\n",
    "# EVALUATE\n",
    "total_loss, n_batch = 0, 0\n",
    "for batch in tl.iterate.minibatches(inputs=XTest, targets=yTest, batch_size=batch_size, shuffle=True):\n",
    "    b_images, b_labels = batch\n",
    "    _loss, out = sess.run([testLoss, yOutputTest],{XInput: b_images, yInput: b_labels})\n",
    "    total_loss += _loss\n",
    "    n_batch += 1\n",
    "    for label,output in zip(b_labels, out):\n",
    "        print(label.shape, output.shape, sep = \"\\n\")\n",
    "        metric(output, labels, m)\n",
    "\n",
    "print(\" **\"+\" \"*17+\"test -- loss: %f\" %(total_loss/n_batch))\n",
    "print(\" task: {}\".format(task))\n",
    "m_avg = avg_metrics(m)\n",
    "df = pd.DataFrame(data=[m_avg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy_avg': nan,\n",
       " 'Precision_avg': nan,\n",
       " 'F_score_avg': nan,\n",
       " 'Recall_avg': nan,\n",
       " 'TP': 0.0,\n",
       " 'FP': 0.0,\n",
       " 'FN': 0.0,\n",
       " 'TN': 0.0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
