{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.layers import *\n",
    "import tensorlayer as tl\n",
    "from Preprocessing import *\n",
    "import time\n",
    "from cv2 import cv2 as cv\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TL] [!] checkpoint exists ...\n",
      "[TL] [!] samples/all exists ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"checkpoint\"\n",
    "tl.files.exists_or_mkdir(save_dir)\n",
    "tl.files.exists_or_mkdir(\"samples/{}\".format(task))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "13\n",
      "28\n",
      "(1, 240, 240, 153)\n",
      "(1, 240, 240, 153)\n",
      "(1, 240, 240, 153)\n",
      "(1, 240, 240, 153)\n",
      "{'DWI': {'mean': 21.078682, 'std': 44.95277}, 'Flair': {'mean': 24.302284, 'std': 50.49608}, 'T1': {'mean': 31.60154, 'std': 63.932735}, 'T2': {'mean': 44.153976, 'std': 92.98761}}\n",
      " HGG Validation\n",
      "finished 12\n",
      "finished 13\n",
      " HGG Train\n",
      "finished 1\n",
      "finished 2\n",
      "finished 3\n",
      "finished 4\n",
      "finished 5\n",
      "finished 6\n",
      "finished 7\n",
      "finished 8\n",
      "finished 9\n",
      "finished 10\n",
      "finished 11\n",
      "finished 12\n",
      "(1836, 240, 240, 4)\n",
      "(1836, 240, 240)\n"
     ]
    }
   ],
   "source": [
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = dataset.X_train_input\n",
    "yTrain = dataset.X_train_target[:, :, :, np.newaxis]\n",
    "XTest = dataset.X_dev_input\n",
    "yTest = dataset.X_dev_target[:, :, :, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = (yTrain > 0).astype(int)\n",
    "yTest = (yTest > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "lr = 0.0001\n",
    "n_epoch = 120\n",
    "evalEpoch = 100\n",
    "dropout_value = 0.05\n",
    "print_freq_step = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Input: size of image: 240 240 4\n",
      " * Input: size of image: 240 240 4\n",
      "[TL]   [*] geting variables with u_net_attention\n",
      "[TL]   got   0: u_net_attention/conv1_l1_1/kernel:0   (3, 3, 4, 64)\n",
      "[TL]   got   1: u_net_attention/conv1_l1_1/bias:0   (64,)\n",
      "[TL]   got   2: u_net_attention/batch_normalization/gamma:0   (64,)\n",
      "[TL]   got   3: u_net_attention/batch_normalization/beta:0   (64,)\n",
      "[TL]   got   4: u_net_attention/convl1_2/kernel:0   (3, 3, 4, 64)\n",
      "[TL]   got   5: u_net_attention/convl1_2/bias:0   (64,)\n",
      "[TL]   got   6: u_net_attention/batch_normalization_1/gamma:0   (64,)\n",
      "[TL]   got   7: u_net_attention/batch_normalization_1/beta:0   (64,)\n",
      "[TL]   got   8: u_net_attention/conv1_l2_1/kernel:0   (3, 3, 64, 128)\n",
      "[TL]   got   9: u_net_attention/conv1_l2_1/bias:0   (128,)\n",
      "[TL]   got  10: u_net_attention/batch_normalization_2/gamma:0   (128,)\n",
      "[TL]   got  11: u_net_attention/batch_normalization_2/beta:0   (128,)\n",
      "[TL]   got  12: u_net_attention/convl2_2/kernel:0   (3, 3, 64, 128)\n",
      "[TL]   got  13: u_net_attention/convl2_2/bias:0   (128,)\n",
      "[TL]   got  14: u_net_attention/batch_normalization_3/gamma:0   (128,)\n",
      "[TL]   got  15: u_net_attention/batch_normalization_3/beta:0   (128,)\n",
      "[TL]   got  16: u_net_attention/conv1_l3_1/kernel:0   (3, 3, 128, 256)\n",
      "[TL]   got  17: u_net_attention/conv1_l3_1/bias:0   (256,)\n",
      "[TL]   got  18: u_net_attention/batch_normalization_4/gamma:0   (256,)\n",
      "[TL]   got  19: u_net_attention/batch_normalization_4/beta:0   (256,)\n",
      "[TL]   got  20: u_net_attention/convl3_2/kernel:0   (3, 3, 128, 256)\n",
      "[TL]   got  21: u_net_attention/convl3_2/bias:0   (256,)\n",
      "[TL]   got  22: u_net_attention/batch_normalization_5/gamma:0   (256,)\n",
      "[TL]   got  23: u_net_attention/batch_normalization_5/beta:0   (256,)\n",
      "[TL]   got  24: u_net_attention/conv1_l4_1/kernel:0   (3, 3, 256, 512)\n",
      "[TL]   got  25: u_net_attention/conv1_l4_1/bias:0   (512,)\n",
      "[TL]   got  26: u_net_attention/batch_normalization_6/gamma:0   (512,)\n",
      "[TL]   got  27: u_net_attention/batch_normalization_6/beta:0   (512,)\n",
      "[TL]   got  28: u_net_attention/convl4_2/kernel:0   (3, 3, 256, 512)\n",
      "[TL]   got  29: u_net_attention/convl4_2/bias:0   (512,)\n",
      "[TL]   got  30: u_net_attention/batch_normalization_7/gamma:0   (512,)\n",
      "[TL]   got  31: u_net_attention/batch_normalization_7/beta:0   (512,)\n",
      "[TL]   got  32: u_net_attention/conv1_l5_1/kernel:0   (3, 3, 512, 1024)\n",
      "[TL]   got  33: u_net_attention/conv1_l5_1/bias:0   (1024,)\n",
      "[TL]   got  34: u_net_attention/batch_normalization_8/gamma:0   (1024,)\n",
      "[TL]   got  35: u_net_attention/batch_normalization_8/beta:0   (1024,)\n",
      "[TL]   got  36: u_net_attention/convl5_2/kernel:0   (3, 3, 512, 1024)\n",
      "[TL]   got  37: u_net_attention/convl5_2/bias:0   (1024,)\n",
      "[TL]   got  38: u_net_attention/batch_normalization_9/gamma:0   (1024,)\n",
      "[TL]   got  39: u_net_attention/batch_normalization_9/beta:0   (1024,)\n",
      "[TL]   got  40: u_net_attention/deconv_1/kernel:0   (3, 3, 512, 1024)\n",
      "[TL]   got  41: u_net_attention/deconv_1/bias:0   (512,)\n",
      "[TL]   got  42: u_net_attention/attn1_g1/kernel:0   (1, 1, 512, 512)\n",
      "[TL]   got  43: u_net_attention/attn1_g1/bias:0   (512,)\n",
      "[TL]   got  44: u_net_attention/attn1_x1/kernel:0   (1, 1, 512, 512)\n",
      "[TL]   got  45: u_net_attention/attn1_x1/bias:0   (512,)\n",
      "[TL]   got  46: u_net_attention/attn1_psi_conv/kernel:0   (1, 1, 512, 512)\n",
      "[TL]   got  47: u_net_attention/attn1_psi_conv/bias:0   (512,)\n",
      "[TL]   got  48: u_net_attention/conv1_ul1_1/kernel:0   (3, 3, 1024, 512)\n",
      "[TL]   got  49: u_net_attention/conv1_ul1_1/bias:0   (512,)\n",
      "[TL]   got  50: u_net_attention/batch_normalization_10/gamma:0   (512,)\n",
      "[TL]   got  51: u_net_attention/batch_normalization_10/beta:0   (512,)\n",
      "[TL]   got  52: u_net_attention/convul1_2/kernel:0   (3, 3, 1024, 512)\n",
      "[TL]   got  53: u_net_attention/convul1_2/bias:0   (512,)\n",
      "[TL]   got  54: u_net_attention/batch_normalization_11/gamma:0   (512,)\n",
      "[TL]   got  55: u_net_attention/batch_normalization_11/beta:0   (512,)\n",
      "[TL]   got  56: u_net_attention/deconv_2/kernel:0   (3, 3, 256, 512)\n",
      "[TL]   got  57: u_net_attention/deconv_2/bias:0   (256,)\n",
      "[TL]   got  58: u_net_attention/attn2_g1/kernel:0   (1, 1, 256, 256)\n",
      "[TL]   got  59: u_net_attention/attn2_g1/bias:0   (256,)\n",
      "[TL]   got  60: u_net_attention/attn2_x1/kernel:0   (1, 1, 256, 256)\n",
      "[TL]   got  61: u_net_attention/attn2_x1/bias:0   (256,)\n",
      "[TL]   got  62: u_net_attention/attn2_psi_conv/kernel:0   (1, 1, 256, 256)\n",
      "[TL]   got  63: u_net_attention/attn2_psi_conv/bias:0   (256,)\n",
      "[TL]   got  64: u_net_attention/conv1_ul2_1/kernel:0   (3, 3, 512, 256)\n",
      "[TL]   got  65: u_net_attention/conv1_ul2_1/bias:0   (256,)\n",
      "[TL]   got  66: u_net_attention/batch_normalization_12/gamma:0   (256,)\n",
      "[TL]   got  67: u_net_attention/batch_normalization_12/beta:0   (256,)\n",
      "[TL]   got  68: u_net_attention/convul2_2/kernel:0   (3, 3, 512, 256)\n",
      "[TL]   got  69: u_net_attention/convul2_2/bias:0   (256,)\n",
      "[TL]   got  70: u_net_attention/batch_normalization_13/gamma:0   (256,)\n",
      "[TL]   got  71: u_net_attention/batch_normalization_13/beta:0   (256,)\n",
      "[TL]   got  72: u_net_attention/deconv_3/kernel:0   (3, 3, 128, 256)\n",
      "[TL]   got  73: u_net_attention/deconv_3/bias:0   (128,)\n",
      "[TL]   got  74: u_net_attention/attn3_g1/kernel:0   (1, 1, 128, 128)\n",
      "[TL]   got  75: u_net_attention/attn3_g1/bias:0   (128,)\n",
      "[TL]   got  76: u_net_attention/attn3_x1/kernel:0   (1, 1, 128, 128)\n",
      "[TL]   got  77: u_net_attention/attn3_x1/bias:0   (128,)\n",
      "[TL]   got  78: u_net_attention/attn3_psi_conv/kernel:0   (1, 1, 128, 128)\n",
      "[TL]   got  79: u_net_attention/attn3_psi_conv/bias:0   (128,)\n",
      "[TL]   got  80: u_net_attention/conv1_ul3_1/kernel:0   (3, 3, 256, 128)\n",
      "[TL]   got  81: u_net_attention/conv1_ul3_1/bias:0   (128,)\n",
      "[TL]   got  82: u_net_attention/batch_normalization_14/gamma:0   (128,)\n",
      "[TL]   got  83: u_net_attention/batch_normalization_14/beta:0   (128,)\n",
      "[TL]   got  84: u_net_attention/convul3_2/kernel:0   (3, 3, 256, 128)\n",
      "[TL]   got  85: u_net_attention/convul3_2/bias:0   (128,)\n",
      "[TL]   got  86: u_net_attention/batch_normalization_15/gamma:0   (128,)\n",
      "[TL]   got  87: u_net_attention/batch_normalization_15/beta:0   (128,)\n",
      "[TL]   got  88: u_net_attention/deconv_4/kernel:0   (3, 3, 64, 128)\n",
      "[TL]   got  89: u_net_attention/deconv_4/bias:0   (64,)\n",
      "[TL]   got  90: u_net_attention/attn4_g1/kernel:0   (1, 1, 64, 64)\n",
      "[TL]   got  91: u_net_attention/attn4_g1/bias:0   (64,)\n",
      "[TL]   got  92: u_net_attention/attn4_x1/kernel:0   (1, 1, 64, 64)\n",
      "[TL]   got  93: u_net_attention/attn4_x1/bias:0   (64,)\n",
      "[TL]   got  94: u_net_attention/attn4_psi_conv/kernel:0   (1, 1, 64, 64)\n",
      "[TL]   got  95: u_net_attention/attn4_psi_conv/bias:0   (64,)\n",
      "[TL]   got  96: u_net_attention/conv1_ul4_1/kernel:0   (3, 3, 128, 64)\n",
      "[TL]   got  97: u_net_attention/conv1_ul4_1/bias:0   (64,)\n",
      "[TL]   got  98: u_net_attention/batch_normalization_16/gamma:0   (64,)\n",
      "[TL]   got  99: u_net_attention/batch_normalization_16/beta:0   (64,)\n",
      "[TL]   got 100: u_net_attention/convul4_2/kernel:0   (3, 3, 128, 64)\n",
      "[TL]   got 101: u_net_attention/convul4_2/bias:0   (64,)\n",
      "[TL]   got 102: u_net_attention/batch_normalization_17/gamma:0   (64,)\n",
      "[TL]   got 103: u_net_attention/batch_normalization_17/beta:0   (64,)\n",
      "[TL]   got 104: u_net_attention/conv_output/kernel:0   (1, 1, 64, 1)\n",
      "[TL]   got 105: u_net_attention/conv_output/bias:0   (1,)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.device(\"/cpu\"):\n",
    "    sess = tf.Session(config = tf.ConfigProto(allow_soft_placement = True))\n",
    "    with tf.device(\"/gpu\"):\n",
    "        \n",
    "        XInput = tf.placeholder(dtype = tf.float32, shape = [batch_size, 240, 240, 4], name = \"input_image\")\n",
    "        yInput = tf.placeholder(dtype = tf.float32, shape = [batch_size, 240, 240, 1], name = \"ground_truth\")\n",
    "        dropout_ph = tf.placeholder_with_default(tf.cast(dropout_value, dtype = tf.float32), shape = [], name = \"dropout_probability\")\n",
    "        \n",
    "        yOutput = UNetWithAttention(XInput, reuse = False, n_out = 1, dropout_ph = dropout_ph)\n",
    "        \n",
    "        yOutputTest = UNetWithAttention(XInput, reuse = True, n_out = 1, dropout_ph = dropout_ph)\n",
    "        \n",
    "        # defining loss\n",
    "        loss = 1 - tl.cost.dice_coe(yOutput, yInput, axis = [0, 1, 2, 3])\n",
    "        testLoss = 1 - tl.cost.dice_coe(yOutputTest, yInput, axis = [0, 1, 2, 3])\n",
    "    \n",
    "    \n",
    "    trainVar = tl.layers.get_variables_with_name('u_net_attention', True, True)\n",
    "    with tf.device('/gpu'):\n",
    "        with tf.variable_scope('learning_rate'):\n",
    "            lrVar = tf.Variable(lr, trainable = False)\n",
    "        \n",
    "        optimizer = tf.train.AdamOptimizer(lrVar).minimize(loss, var_list = trainVar)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # load existing model if exist\n",
    "    saver = tf.train.Saver(var_list = trainVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Preloaded model not available\n",
      "Epoch 0 step 183 1 - dice: 0.395187 time taken: 1.285937secs          \n",
      " ** Epoch [0/120] trained ==> loss: 0.443281 -- time taken: 240.276938sec\n",
      " **                 test -- loss: 0.772260\n",
      " task: all\n",
      "[+] Checkpoint saved in  ./checkpoint/u_net_attention_all.ckpt\n",
      "Epoch 1 step 9 1 - dice: 0.471364 time taken: 1.329287secs          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1442d0c46b88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m## update network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myOutput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mXInput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mb_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myInput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0m_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mn_batch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\razer\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "if os.path.exists(\"./checkpoint/u_net_attention_{}.ckpt\".format(task)) == True:\n",
    "    saver.restore(sess, \"./checkpoint/u_net_attention_{}.ckpt\".format(task))\n",
    "    print(\"[+] Presaved model restored\")\n",
    "else:\n",
    "    print(\"[+] Preloaded model not available\")\n",
    "for epoch in range(0, n_epoch + 1):\n",
    "    epochTime = time.time()\n",
    "    total_loss, n_batch = 0, 0\n",
    "    for batch in tl.iterate.minibatches(inputs=XTrain, targets=yTrain, batch_size=batch_size, shuffle=True):\n",
    "        images, labels = batch\n",
    "        step_time = time.time()\n",
    "        ## data augumentation for a batch of Flair, T1, T1c, T2 images\n",
    "        # and label maps synchronously.\n",
    "        data = tl.prepro.threading_data([_ for _ in zip(images[:,:,:,0, np.newaxis],\n",
    "                images[:,:,:,1, np.newaxis], images[:,:,:,2, np.newaxis],\n",
    "                images[:,:,:,3, np.newaxis], labels)],\n",
    "                fn = DistortImages) # (10, 5, 240, 240, 1)\n",
    "        b_images = data[:,0:4,:,:,:]  # (10, 4, 240, 240, 1)\n",
    "        b_labels = data[:,4,:,:,:]\n",
    "        b_images = b_images.transpose((0,2,3,1,4))\n",
    "        b_images.shape = (batch_size, 240, 240, 4)\n",
    "\n",
    "        ## update network\n",
    "        _, _loss, out = sess.run([optimizer, loss, yOutput], feed_dict = {XInput:b_images, yInput:b_labels})\n",
    "        total_loss += _loss\n",
    "        n_batch += 1\n",
    "        print(\"Epoch %d step %d 1 - dice: %f time taken: %fsecs          \" %(epoch, n_batch, _loss, time.time() - step_time), end = \"\\r\")\n",
    "\n",
    "        if np.isnan(_loss):\n",
    "            exit(\" ** NaN loss found during training, stop training\")\n",
    "\n",
    "        if np.isnan(out).any():\n",
    "            exit(\" ** NaN found in output images during training, stop training\")\n",
    "                \n",
    "    print(\"\\n ** Epoch [%d/%d] trained ==> loss: %f -- time taken: %fsec\" %(epoch, n_epoch, total_loss/n_batch, time.time() - epochTime))\n",
    "    \n",
    "    ## save a predition of training set\n",
    "    for i in range(batch_size):\n",
    "        if np.max(b_images[i]) > 0:\n",
    "            VisualizeImageWithPrediction(b_images[i], b_labels[i], out[i], \"samples/{}/train_{}.png\".format(task, epoch))\n",
    "            break\n",
    "        elif i == batch_size-1:\n",
    "            VisualizeImageWithPrediction(b_images[i], b_labels[i], out[i], \"samples/{}/train_{}.png\".format(task, epoch))\n",
    "    \n",
    "    # EVALUATE\n",
    "    total_loss, n_batch = 0, 0\n",
    "    for batch in tl.iterate.minibatches(inputs=XTest, targets=yTest, batch_size=batch_size, shuffle=True):\n",
    "        b_images, b_labels = batch\n",
    "        _loss, out = sess.run([testLoss, yOutputTest],{XInput: b_images, yInput: b_labels})\n",
    "        total_loss += _loss\n",
    "        n_batch += 1\n",
    "\n",
    "    print(\" **\"+\" \"*17+\"test -- loss: %f\" %(total_loss/n_batch))\n",
    "    print(\" task: {}\".format(task))\n",
    "    ## save a predition of test set\n",
    "    for i in range(batch_size):\n",
    "        if np.max(b_images[i]) > 0:\n",
    "            VisualizeImageWithPrediction(b_images[i], b_labels[i], out[i], \"samples/{}/test_{}.png\".format(task, epoch))\n",
    "            break\n",
    "        elif i == batch_size-1:\n",
    "            VisualizeImageWithPrediction(b_images[i], b_labels[i], out[i], \"samples/{}/test_{}.png\".format(task, epoch))\n",
    "    \n",
    "    savePath = saver.save(sess, \"./checkpoint/u_net_attention_{}.ckpt\".format(task))\n",
    "    print(\"[+] Checkpoint saved in \", savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load metrics.py\n",
    "# Evaluation Metrics - TP, TN, FP, FN, Precision, Recall, Accuracy, F_Score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def metric(prediction, ground_truth, metrics):\n",
    "    \n",
    "    #True Positive (TP): we predict a label of 1, true label is 1.\n",
    "    TP_i = np.sum(np.logical_and(prediction == 1, ground_truth == 1))\n",
    "\n",
    "    # True Negative (TN): we predict a label of 0 (negative), and the true label is 0.\n",
    "    TN_i = np.sum(np.logical_and(prediction == 0, ground_truth == 0))\n",
    "\n",
    "    # False Positive (FP): we predict a label of 1 (positive), but the true label is 0.\n",
    "    FP_i = np.sum(np.logical_and(prediction == 1, ground_truth == 0))\n",
    "\n",
    "    # False Negative (FN): we predict a label of 0 (negative), but the true label is 1.\n",
    "    FN_i = np.sum(np.logical_and(prediction == 0, ground_truth == 1))\n",
    "\n",
    "    P_i = TP_i/(TP_i+FP_i) #Precision for ith test-reference sample\n",
    "    R_i = TP_i/(TP_i+FN_i) #Recall for ith test-reference sample\n",
    "    F_score_i = 2*P_i*R_i/(P_i+R_i) #F_score for ith test-reference sample\n",
    "    Accuracy_i = (TP_i+TN_i)/(TP_i+TN_i+FP_i+FN_i) #Accuracy for ith test-reference sample\n",
    "    \n",
    "\n",
    "    #Confusion matrix for ith example\n",
    "    metrics[\"Confusion\"][0].append(TP_i)\n",
    "    metrics[\"Confusion\"][1].append(FP_i)\n",
    "    metrics[\"Confusion\"][2].append(FN_i)\n",
    "    metrics[\"Confusion\"][3].append(FP_i)\n",
    "    \n",
    "    #Appending metrics of ith sample\n",
    "    metrics[\"Precision\"].append(P_i)\n",
    "    metrics[\"Recall\"].append(R_i)\n",
    "    metrics[\"F_score\"].append(F_score_i)\n",
    "    metrics[\"Accuracy\"].append(Accuracy_i)\n",
    "\n",
    "def avg_metrics(metrics):\n",
    "    metrics_avg = {}\n",
    "    metrics_avg[\"Accuracy_avg\"] = np.sum(metrics[\"Accuracy\"])/np.size(metrics[\"Accuracy\"])\n",
    "    metrics_avg[\"Precision_avg\"] = np.sum(metrics[\"Precision\"])/np.size(metrics[\"Precision\"])\n",
    "    metrics_avg[\"F_score_avg\"] = np.sum(metrics[\"F_score\"])/np.size(metrics[\"F_score\"])\n",
    "    metrics_avg[\"Recall_avg\"] = np.sum(metrics[\"Recall\"])/np.size(metrics[\"Recall\"])\n",
    "    metrics_avg[\"TP\"] = np.sum(metrics[\"Confusion\"][0])/np.size(metrics[\"Confusion\"][0])\n",
    "    metrics_avg[\"FP\"] = np.sum(metrics[\"Confusion\"][1])/np.size(metrics[\"Confusion\"][1])\n",
    "    metrics_avg[\"FN\"] = np.sum(metrics[\"Confusion\"][2])/np.size(metrics[\"Confusion\"][2])\n",
    "    metrics_avg[\"TN\"] = np.sum(metrics[\"Confusion\"][3])/np.size(metrics[\"Confusion\"][3])\n",
    "    return metrics_avg\n",
    "\n",
    "def exportcsv(metric_dict):\n",
    "    df = pd.DataFrame(data=[metric_dict])\n",
    "    df.to_csv(\"./metrics.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample Pairs of Predictions & Ground_Truth Images of size 240*2\n",
    "im_1=np.random.randint(2, size=(240, 240, 1))\n",
    "im_2=np.random.randint(2, size=(240, 240, 1))\n",
    "im_3=np.random.randint(2, size=(240, 240, 1))\n",
    "im_4=np.random.randint(2, size=(240, 240, 1))\n",
    "im_5=np.random.randint(2, size=(240, 240, 1))\n",
    "im_6=np.random.randint(2, size=(240, 240, 1))\n",
    "m = {'Precision':[], 'Recall':[], 'Accuracy':[], 'F_score':[], 'Confusion':[[],[],[],[]]}\n",
    "metric(im_1, im_2, m)\n",
    "metric(im_3, im_4, m)\n",
    "metric(im_5, im_6, m)\n",
    "m_avg = avg_metrics(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy_avg</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>F_score_avg</th>\n",
       "      <th>Precision_avg</th>\n",
       "      <th>Recall_avg</th>\n",
       "      <th>TN</th>\n",
       "      <th>TP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.499907</td>\n",
       "      <td>14455.333333</td>\n",
       "      <td>14350.0</td>\n",
       "      <td>0.500081</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.499167</td>\n",
       "      <td>14350.0</td>\n",
       "      <td>14407.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy_avg            FN       FP  F_score_avg  Precision_avg  \\\n",
       "0      0.499907  14455.333333  14350.0     0.500081          0.501   \n",
       "\n",
       "   Recall_avg       TN            TP  \n",
       "0    0.499167  14350.0  14407.333333  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data=[m_avg])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
