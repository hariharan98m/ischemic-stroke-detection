{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#imports\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorlayer as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vizualise(img):\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(img), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_scan(path):\n",
    "    'read the images, core label, penumbra label, merged label'\n",
    "    img = nib.load(str(path))\n",
    "    data = img.get_fdata()\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/1/1OT.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(230, 230, 154)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_scan(path).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = read_scan(path)[:,:,101:102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "#imports\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorlayer as tl\n",
    "import pixtopix\n",
    "#%%\n",
    "#set all the vars and the hyper params\n",
    "data_dir = Path.cwd().parent / 'data'\n",
    "formatted_data_dir = Path.cwd().parent / 'formatted_data'\n",
    "IMG_WIDTH = 96\n",
    "IMG_HEIGHT = 96\n",
    "NUM_FRAMES = 7\n",
    "MRI_SCAN_TYPES = 7\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "TOTAL_LENGTH = 71*30\n",
    "TRAIN_LENGTH = int(0.90* TOTAL_LENGTH)\n",
    "VAL_LENGTH = int(0.01 * TOTAL_LENGTH)\n",
    "TEST_LENGTH = int(0.09* TOTAL_LENGTH)\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "LABEL = 'c'\n",
    "VAL_BATCH_SIZE = 64\n",
    "\n",
    "#Data loading, processing\n",
    "\n",
    "def read_ct_scan(path):\n",
    "    'read the images, core label, penumbra label, merged label'\n",
    "    img = nib.load(str(path))\n",
    "    data = img.get_fdata()\n",
    "    return tf.convert_to_tensor(data)\n",
    "\n",
    "def load_preprocess(paths):\n",
    "    '''\n",
    "    read the ct scans, masks from the paths list and stack them along the z.\n",
    "    transpose the last dimension to the first as a batch and split the entire dataset into discrete images\n",
    "    :param paths:\n",
    "    :return: preprocessed images\n",
    "    '''\n",
    "    imgs_list = list(map(read_ct_scan, paths))\n",
    "    imgs_stack = tf.stack(imgs_list, axis=-1, name='img_stack')\n",
    "    #transpose along the mri/label types. 1st dim is the frames\n",
    "    blob = tf.transpose(imgs_stack, perm=[2, 0, 1, 3])\n",
    "    resized_blob = resize(blob, IMG_HEIGHT, IMG_WIDTH)\n",
    "    #unstack along the first dim to get component single training sample- no use as the yield dataset generator again stacks back to give stacked axis=0\n",
    "    images = tf.unstack(resized_blob, axis=0)\n",
    "    return images\n",
    "\n",
    "#use it to get all the paths for all the images, masks\n",
    "def get_paths(scan):\n",
    "    scans = sorted(list(data_dir.glob(str(scan)+'/V*/*.nii')))\n",
    "    masks = sorted(list(data_dir.glob(str(scan)+'/['+LABEL+']*/V*/*.nii')))\n",
    "    #convert list to string so that the dataset can be a tensor\n",
    "    return scans+ masks\n",
    "\n",
    "\n",
    "def data_generator():\n",
    "    '''\n",
    "        use the data generator function to generate all the samples from all the .nii\n",
    "    :return: sample\n",
    "    '''\n",
    "    paths_db = list(map(get_paths, np.arange(1,31)))\n",
    "    for paths in paths_db:\n",
    "        for sample in load_preprocess(paths):\n",
    "            yield sample\n",
    "\n",
    "\n",
    "def one_hot_blob_merged(mask_image):\n",
    "    return tf.split(tf.one_hot(tf.cast(tf.squeeze(mask_image, axis=-1), dtype=tf.int64), depth=3, axis=-1), [1, 2], axis=-1)\n",
    "\n",
    "# image preprocessing functions for augmentation\n",
    "def normalize(input_image):\n",
    "    # we need not normalize the input mask, as the values are already in the range of -1 to 1\n",
    "    # norm_mask = None\n",
    "    # if LABEL == 'c' or LABEL=='p':\n",
    "    #     # no need to transform, as the image is full of zeros and ones\n",
    "    #     norm_mask = mask_image\n",
    "    # if LABEL=='m':\n",
    "    #     _, norm_mask  = one_hot_blob_merged(mask_image)\n",
    "\n",
    "    return tf.cast(input_image, tf.float32) / 128.0 - 1  #, norm_mask\n",
    "\n",
    "def resize(input_image_stack, height, width):\n",
    "    return tf.image.resize(input_image_stack, [height, width],\n",
    "                           method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "\n",
    "\n",
    "def random_crop(stacked_image):\n",
    "    return tf.image.random_crop(stacked_image, size=[IMG_HEIGHT, IMG_WIDTH, tf.shape(stacked_image)[-1]])\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(real_image, mask_image):\n",
    "\n",
    "    # do all this on a stack size of scan_types + mask_count\n",
    "    datapoint = tf.concat([real_image, mask_image], axis=-1)\n",
    "\n",
    "    # resize to 117% of the actual image size\n",
    "    datapoint = resize(datapoint, 108, 108)\n",
    "\n",
    "    # randomly crop it back to desired size of 96x96\n",
    "    datapoint = random_crop(datapoint)\n",
    "\n",
    "    # split the stack into input and mask\n",
    "    real_image, mask_image = tf.split(datapoint, [NUM_FRAMES, tf.shape(datapoint)[-1] - NUM_FRAMES], axis=-1)\n",
    "\n",
    "    # random mirroring\n",
    "    if np.random.uniform(()) > 0.5:\n",
    "        real_image = tf.image.flip_left_right(real_image)\n",
    "        mask_image = tf.image.flip_left_right(mask_image)\n",
    "\n",
    "    real_image = normalize(real_image)\n",
    "\n",
    "    return real_image, mask_image\n",
    "\n",
    "\n",
    "def load_image_test(real_image, mask_image):\n",
    "\n",
    "    datapoint = tf.concat([real_image, mask_image], axis=-1)\n",
    "\n",
    "    # Resize the image stack\n",
    "    datapoint = resize(datapoint, IMG_HEIGHT, IMG_WIDTH)\n",
    "\n",
    "    # split the stack into input and mask\n",
    "    real_image, mask_image = tf.split(datapoint, [NUM_FRAMES, tf.shape(datapoint)[-1] - NUM_FRAMES], axis=-1)\n",
    "\n",
    "    # norm images\n",
    "    real_image = normalize(real_image)\n",
    "\n",
    "    return real_image, mask_image\n",
    "\n",
    "def is_all_zero(tensor):\n",
    "    real_image, mask_image= tf.split(tensor, num_or_size_splits=[7, 1], axis=-1)\n",
    "    real, mask = normalize(real_image, mask_image)\n",
    "    core, penumbra = tf.split(mask, num_or_size_splits=[1, 1], axis=-1)\n",
    "    return tf.equal(tf.reduce_sum(core+ penumbra), 0)\n",
    "\n",
    "def allow_mask_area(image, mask):\n",
    "    return tf.math.greater(tf.reduce_sum(tf.cast(tf.math.equal(mask, 1.0), dtype= tf.float32))/ (96.0 * 96.0), 0.0)\n",
    "\n",
    "def barricade_mask_area(image, mask):\n",
    "    return tf.math.equal(tf.reduce_sum(tf.cast(tf.math.equal(mask, 1.0), dtype= tf.float32))/ (96.0 * 96.0), 0.0)\n",
    "\n",
    "\n",
    "def just_load_images(datapoint):\n",
    "    # split the stack into input and mask\n",
    "    real_image, mask_image = tf.split(datapoint, [NUM_FRAMES, 1], axis=-1)\n",
    "\n",
    "    norm_mask = None\n",
    "    if LABEL == 'c' or LABEL == 'p':\n",
    "        # no need to transform, as the image is full of zeros and ones\n",
    "        norm_mask = mask_image\n",
    "    if LABEL == 'm':\n",
    "        _, norm_mask = one_hot_blob_merged(mask_image)\n",
    "\n",
    "    return real_image, norm_mask\n",
    "\n",
    "\n",
    "def get_dataset_handle(label):\n",
    "    global TRAIN_LENGTH, VAL_LENGTH, TEST_LENGTH, LABEL\n",
    "    LABEL = label\n",
    "    ds = tf.data.Dataset.from_generator(data_generator, output_shapes=(96, 96, MRI_SCAN_TYPES + 1),\n",
    "                                        output_types=tf.float32)\n",
    "\n",
    "    shuffled_ds = ds.shuffle(buffer_size=BUFFER_SIZE)\n",
    "    #ds.map(lambda x: is_all_zero(x)).reduce(np.float32(0), lambda x, y: x + y)\n",
    "\n",
    "\n",
    "    # -------START Deviation ---------\n",
    "    shuffled_ds = shuffled_ds.map(just_load_images)\n",
    "    shuffled_ds_filtered_with_non_zero_mask = shuffled_ds.filter(allow_mask_area)\n",
    "    shuffled_ds_filtered_with_zero_mask = shuffled_ds.filter(barricade_mask_area)\n",
    "\n",
    "    # Get filter count\n",
    "    count_filtered_set_with_non_zero_mask = shuffled_ds_filtered_with_non_zero_mask.map(lambda image, mask: 1.0).reduce(\n",
    "        np.float32(0), lambda x, y: x + y)\n",
    "    count_filtered_set_with_zero_mask = shuffled_ds_filtered_with_zero_mask.map(lambda image, mask: 1.0).reduce(np.float32(0), lambda x,y: x + y)\n",
    "\n",
    "    print('filtered set with non-zero mask', count_filtered_set_with_non_zero_mask.numpy())\n",
    "    print('filtered set with zero mask', count_filtered_set_with_zero_mask.numpy())\n",
    "\n",
    "    TRAIN_LENGTH = int(0.9 * count_filtered_set_with_non_zero_mask)\n",
    "    VAL_LENGTH = int(0.01 * count_filtered_set_with_non_zero_mask)\n",
    "    TEST_LENGTH = int(0.09 * count_filtered_set_with_non_zero_mask)\n",
    "\n",
    "    train = shuffled_ds_filtered_with_non_zero_mask.take(TRAIN_LENGTH)\\\n",
    "            .concatenate(shuffled_ds_filtered_with_zero_mask.take(int(0.5 * TRAIN_LENGTH)))\n",
    "\n",
    "    shuffled_ds_filtered_with_non_zero_mask.skip(TRAIN_LENGTH)\n",
    "    shuffled_ds_filtered_with_zero_mask.skip(int(0.5* TRAIN_LENGTH))\n",
    "\n",
    "    TRAIN_LENGTH+= int(0.5*TRAIN_LENGTH)\n",
    "\n",
    "    val = shuffled_ds_filtered_with_non_zero_mask.take(VAL_LENGTH)\\\n",
    "            .concatenate(shuffled_ds_filtered_with_zero_mask.take(int(0.5 * VAL_LENGTH)))\n",
    "\n",
    "    shuffled_ds_filtered_with_non_zero_mask.skip(VAL_LENGTH)\n",
    "    shuffled_ds_filtered_with_zero_mask.skip(int(0.5 * VAL_LENGTH))\n",
    "\n",
    "    VAL_LENGTH+= int(0.5 * VAL_LENGTH)\n",
    "\n",
    "    test = shuffled_ds_filtered_with_non_zero_mask.take(TEST_LENGTH) \\\n",
    "        .concatenate(shuffled_ds_filtered_with_zero_mask.take(int(0.5 * TEST_LENGTH)))\n",
    "\n",
    "    TEST_LENGTH+= int(0.5 * TEST_LENGTH)\n",
    "\n",
    "    #----------- END Deviation -----------\n",
    "\n",
    "    # #Split the data into train, val and test\n",
    "    # train = shuffled_ds.take(TRAIN_LENGTH)  # take out train length num of elements\n",
    "    # shuffled_ds.skip(TRAIN_LENGTH)  # skip those elements on the buffer\n",
    "    #\n",
    "    # val = shuffled_ds.take(VAL_LENGTH)  # pull out a new sample\n",
    "    # shuffled_ds.skip(VAL_LENGTH)  # skip those\n",
    "    #\n",
    "    # test = shuffled_ds.take(TEST_LENGTH)\n",
    "    #\n",
    "    # #Apply the preprocessing function\n",
    "    # train = train.map(just_load_images, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    #\n",
    "    # # Filter the dataset\n",
    "    # filtered_set_with_non_zero_mask = train.filter(allow_mask_area)\n",
    "    # # Get filter count\n",
    "    # count_filtered_set_with_non_zero_mask = filtered_set_with_non_zero_mask.map(lambda image, mask: 1.0).reduce(np.float32(0), lambda x, y: x+ y)\n",
    "    #\n",
    "    # # Filter dataset with zero core penumbra masks\n",
    "    # filtered_set_with_zero_mask = train.filter(barricade_mask_area)\n",
    "    # # Get filter count\n",
    "    # count_filtered_set_with_zero_mask = filtered_set_with_zero_mask.map(lambda image, mask: 1.0).reduce(np.float32(0), lambda x, y: x + y)\n",
    "    #\n",
    "    # count_with_non_zero_mask = count_filtered_set_with_non_zero_mask.numpy()\n",
    "    # count_with_zero_mask = count_filtered_set_with_zero_mask.numpy()\n",
    "    #\n",
    "    # print('non zero masks %d' % int(count_with_non_zero_mask))\n",
    "    # print('zero masks %d' % int(count_with_zero_mask))\n",
    "    #\n",
    "    # # Get the filtered training set\n",
    "    # train = filtered_set_with_non_zero_mask.take(count_with_non_zero_mask) \\\n",
    "    #              .concatenate(filtered_set_with_zero_mask.take(int(0.5 * count_with_non_zero_mask)))\n",
    "    #\n",
    "    # val, test = val.map(just_load_images), test.map(just_load_images)\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "def parse(sample):\n",
    "  image = tf.io.parse_tensor(sample['image'], out_type=tf.float32)\n",
    "  image = tf.reshape(image, [96, 96, 7])\n",
    "\n",
    "  mask = tf.io.parse_tensor(sample['mask'], out_type=tf.float32)\n",
    "  if LABEL=='c' or LABEL=='p':\n",
    "    mask = tf.reshape(mask, [96, 96, 1])\n",
    "  elif LABEL =='m':\n",
    "    mask = tf.reshape(mask, [96, 96, 2])\n",
    "\n",
    "  return (image, mask)\n",
    "\n",
    "def read_from_tensor_dataset(label):\n",
    "    global LABEL\n",
    "    LABEL = label\n",
    "\n",
    "    if (formatted_data_dir / LABEL / 'train.tfrecords').is_file():\n",
    "        print('Reading off the TFRecord for label \\'{}\\''.format(label))\n",
    "        train = tf.data.TFRecordDataset(str(formatted_data_dir / LABEL / 'train.tfrecords'))\n",
    "        val = tf.data.TFRecordDataset(str(formatted_data_dir / LABEL / 'val.tfrecords'))\n",
    "        test = tf.data.TFRecordDataset(str(formatted_data_dir / LABEL / 'test.tfrecords'))\n",
    "\n",
    "        # Create a description of the features.\n",
    "        feature_description = {\n",
    "            'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "            'mask': tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "        }\n",
    "\n",
    "        _parse_record = lambda example_proto: tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "        train, val, test = train.map(_parse_record), val.map(_parse_record), test.map(_parse_record)\n",
    "        train_dataset, val_dataset, test_dataset = train.map(parse), val.map(parse), test.map(parse)\n",
    "\n",
    "        train_dataset = train_dataset.map(load_image_train).cache().shuffle(BUFFER_SIZE).repeat().batch(BATCH_SIZE)\n",
    "        train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "        test_dataset = test_dataset.map(load_image_test).batch(BATCH_SIZE)\n",
    "        val_dataset = val_dataset.map(load_image_test).batch(BATCH_SIZE)\n",
    "\n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "    else:\n",
    "        print('No existing records for label \\'{}\\''.format(label))\n",
    "        train, val, test = get_dataset_handle()\n",
    "        write_to_tensor_dataset(train, val, test)\n",
    "        return read_from_tensor_dataset(label)\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def serialize_example(img, mask):\n",
    "    feature = {\n",
    "        'image': _bytes_feature(tf.io.serialize_tensor(img)),\n",
    "        'mask': _bytes_feature(tf.io.serialize_tensor(mask))\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "\n",
    "def write_to_tensor_dataset(train, val, test):\n",
    "    # Map it to a stacked image.\n",
    "    #concat_image_mask = lambda images, masks: tf.concat([images, masks], axis=-1)\n",
    "    #train, val, test = train.map(concat_image_mask), val.map(concat_image_mask), test.map(concat_image_mask)\n",
    "\n",
    "    # val_tfrec = tf.data.experimental.TFRecordWriter(str(formatted_data_dir / LABEL / 'val.tfrec'))\n",
    "    # test_tfrec = tf.data.experimental.TFRecordWriter(str(formatted_data_dir / LABEL / 'test.tfrec'))\n",
    "\n",
    "    #train = train.map(tf_serialize_example)\n",
    "    #filename = 'test.tfrecord'\n",
    "    #writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "    #writer.write(serialized_features_dataset)\n",
    "\n",
    "    with tf.io.TFRecordWriter(str(formatted_data_dir / LABEL / 'train.tfrecords')) as train_writer:\n",
    "        for img, mask in train:\n",
    "            tf_string = serialize_example(img, mask)\n",
    "            train_writer.write(tf_string)\n",
    "\n",
    "    with tf.io.TFRecordWriter(str(formatted_data_dir / LABEL / 'val.tfrecords')) as val_writer:\n",
    "        for img, mask in val:\n",
    "            tf_string = serialize_example(img, mask)\n",
    "            val_writer.write(tf_string)\n",
    "\n",
    "    with tf.io.TFRecordWriter(str(formatted_data_dir / LABEL / 'test.tfrecords')) as test_writer:\n",
    "        for img, mask in test:\n",
    "            tf_string = serialize_example(img, mask)\n",
    "            test_writer.write(tf_string)\n",
    "\n",
    "\n",
    "\n",
    "    # serialize the tensors\n",
    "    #train, val, test = train.take(2).map(tf.io.serialize_tensor), val.take(5).map(tf.io.serialize_tensor), test.take(5).map(tf.io.serialize_tensor)\n",
    "\n",
    "\n",
    "    #\n",
    "    # for img in train:\n",
    "    #     serialize_example(img)\n",
    "    #\n",
    "    # print('Writing to disk...')\n",
    "    # print(train)\n",
    "    # train_tfrec.write(train)\n",
    "    # train_tfrec.close()\n",
    "    #\n",
    "    # val_tfrec.write(val)\n",
    "    # val_tfrec.close()\n",
    "    #\n",
    "    # test_tfrec.write(test)\n",
    "    # test_tfrec.close()\n",
    "    # print('Written to disk')\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    _, _, _ = read_from_tensor_dataset('m')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
